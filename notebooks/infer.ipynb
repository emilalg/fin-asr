{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import datasets\n",
    "ds = datasets.load_from_disk('../data/hf')\n",
    "ds = ds['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASRAlphabet:\n",
    "    def __init__(self, alphabet_string):\n",
    "        self.alphabet = list(alphabet_string)\n",
    "        self.alphabet.append('<blank>')  # Adding blank token\n",
    "        self.char_to_index = {char: index for index, char in enumerate(self.alphabet)}\n",
    "        self.index_to_char = {index: char for index, char in enumerate(self.alphabet)}\n",
    "\n",
    "    def text_to_array(self, text):\n",
    "        return [self.char_to_index[char] for char in str.lower(text) if char in self.char_to_index]\n",
    "\n",
    "    def array_to_text(self, array):\n",
    "        return ''.join(self.index_to_char.get(int(index), '<UNK>') for index in array)\n",
    "    \n",
    "alphabet = ASRAlphabet(alphabet_string='abcdefghijklmnopqrstuvwxyzåäö ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import torch\n",
    "\n",
    "mel_spectrogram_converter = torchaudio.transforms.MelSpectrogram(\n",
    "        sample_rate=16000,\n",
    "        n_fft=400,\n",
    "        n_mels=40\n",
    ")\n",
    "\n",
    "# from audio_utils\n",
    "def preprocess_audio(batch):\n",
    "\n",
    "    max_input_length = 0\n",
    "    max_label_length = 0\n",
    "\n",
    "    audio = []\n",
    "    label = []\n",
    "    audio_length = []\n",
    "    label_length = []\n",
    "\n",
    "    for item in batch:\n",
    "        t1 = torch.tensor(item['audio']['array']).float()\n",
    "\n",
    "        sample_rate = item['audio']['sampling_rate']\n",
    "        if sample_rate != 16000:\n",
    "            resampler = torchaudio.transforms.Resample(sample_rate, 16000)\n",
    "            t1 = resampler(t1)\n",
    "        \n",
    "        t1 = torchaudio.functional.preemphasis(t1)\n",
    "\n",
    "        mel_spectrogram = mel_spectrogram_converter(t1)\n",
    "\n",
    "        # Apply log to the mel spectrogram\n",
    "        mel_spectrogram = torch.log(mel_spectrogram + 1e-9)\n",
    "\n",
    "        # Normalize the spectrogram\n",
    "        mel_spectrogram = (mel_spectrogram - mel_spectrogram.mean()) / mel_spectrogram.std()\n",
    "\n",
    "        # Transpose the mel spectrogram to correct dimension (time, mels)\n",
    "        mel_spectrogram = mel_spectrogram.transpose(0, 1)\n",
    "\n",
    "        # eka bugi löyty (väärä shape (1))\n",
    "        max_input_length = max(max_input_length, mel_spectrogram.shape[0])\n",
    "\n",
    "        sentence = torch.tensor(alphabet.text_to_array(str.lower(item['sentence'])))\n",
    "\n",
    "        max_label_length = max(max_label_length, len(sentence))\n",
    "\n",
    "        audio.append(mel_spectrogram)\n",
    "        label.append(sentence)\n",
    "        audio_length.append(mel_spectrogram.shape[0])\n",
    "        label_length.append(len(sentence))\n",
    "\n",
    "    audio_padded = map(lambda x: torch.nn.functional.pad(x, (0, 0, 0, max_input_length - x.size(0))), audio)\n",
    "    blank_index = len(alphabet.alphabet) - 1  # Index of the blank token\n",
    "    labels_padded = map(lambda x: torch.nn.functional.pad(x, (0, max_label_length - len(x)), value=blank_index), label)\n",
    "\n",
    "    return (list(audio_padded), list(labels_padded), audio_length, label_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio, label, audio_len, label_len = preprocess_audio([ds[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LSTMCTC(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes, num_layers, dropout_rate):\n",
    "        super(LSTMCTC, self).__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional=True,\n",
    "            dropout=dropout_rate,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_len, input_size)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.dropout(x)  \n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMCTC(\n",
       "  (lstm): LSTM(40, 320, num_layers=4, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  (fc): Linear(in_features=640, out_features=31, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTMCTC(\n",
    "        input_size=40,  # mels\n",
    "        hidden_size=320,\n",
    "        num_layers=4,\n",
    "        num_classes=len(alphabet.alphabet),\n",
    "        dropout_rate=0.2\n",
    ")\n",
    "model.load_state_dict(torch.load('../gd.pth', weights_only=True))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import List\n",
    "\n",
    "class SimpleDecoder:\n",
    "    def __init__(self, alphabet):\n",
    "        self.alphabet = alphabet\n",
    "        self.blank_index = len(alphabet)  # Assuming blank is the last index\n",
    "\n",
    "    def decode(self, log_probs: torch.Tensor) -> List[str]:\n",
    "        \"\"\"\n",
    "        Decode log probabilities to text using greedy decoding.\n",
    "        \n",
    "        Args:\n",
    "        log_probs (torch.Tensor): Log probabilities from the model \n",
    "                                  Shape: (batch_size, sequence_length, num_classes)\n",
    "        \n",
    "        Returns:\n",
    "        List[str]: Decoded texts for each item in the batch\n",
    "        \"\"\"\n",
    "        # Get the most likely class at each step\n",
    "        predictions = torch.argmax(log_probs, dim=-1)  # Shape: (batch_size, sequence_length)\n",
    "        \n",
    "        batch_texts = []\n",
    "        for batch_item in predictions:\n",
    "            text = self._decode_prediction(batch_item)\n",
    "            batch_texts.append(text)\n",
    "        \n",
    "        return batch_texts\n",
    "\n",
    "    def _decode_prediction(self, prediction: torch.Tensor) -> str:\n",
    "        \"\"\"\n",
    "        Decode a single prediction sequence to text.\n",
    "        \n",
    "        Args:\n",
    "        prediction (torch.Tensor): Prediction sequence for a single item\n",
    "                                   Shape: (sequence_length,)\n",
    "        \n",
    "        Returns:\n",
    "        str: Decoded text\n",
    "        \"\"\"\n",
    "        decoded = []\n",
    "        previous = None\n",
    "        for p in prediction:\n",
    "            p = p.item()\n",
    "            if p != previous and p != self.blank_index:\n",
    "                if p < len(self.alphabet):\n",
    "                    decoded.append(self.alphabet[p])\n",
    "            previous = p\n",
    "        \n",
    "        return ''.join(decoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 505, 31])\n"
     ]
    }
   ],
   "source": [
    "audio = torch.stack(audio, dim=0)\n",
    "output = model(audio)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 505, 31]) ['hirvityshyökkäsiitä lähinnä olevan tankin kimppuun'] Hirvitys hyökkäsi sitä lähinnä olevan tankin kimppuun.\n"
     ]
    }
   ],
   "source": [
    "dec = SimpleDecoder(alphabet=alphabet.alphabet)\n",
    "log_probs = F.log_softmax(output, dim=-1)\n",
    "#log_probs = F.log_softmax(output, dim=2).permute(1, 0, 2)\n",
    "print(log_probs.shape, str(dec.decode(log_probs)).replace('<blank>', ''), ds[0]['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio, label, audio_len, label_len = preprocess_audio([ds[0], ds[1], ds[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 505, 40])\n"
     ]
    }
   ],
   "source": [
    "audio = torch.stack(audio, dim=0)\n",
    "print(audio.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 54]) tensor([53, 54, 20])\n"
     ]
    }
   ],
   "source": [
    "labels = torch.stack(label, dim=0)\n",
    "label_len = torch.tensor(label_len)\n",
    "print(labels.shape, label_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 7,  8, 17, 21,  8, 19, 24, 18, 29,  7, 24, 28, 10, 10, 27, 18,  8, 29,\n",
      "         18,  8, 19, 27, 29, 11, 27,  7,  8, 13, 13, 27, 29, 14, 11,  4, 21,  0,\n",
      "         13, 29, 19,  0, 13, 10,  8, 13, 29, 10,  8, 12, 15, 15, 20, 20, 13, 30],\n",
      "        [27, 27, 13,  4, 18, 19, 27, 12, 12,  4, 29, 18,  8,  8, 18, 29, 19, 27,\n",
      "         12, 27, 13, 18, 20, 20, 13, 19,  0,  8, 18, 19,  4, 13, 29, 19,  0, 17,\n",
      "         10,  8, 18, 19, 20, 18, 19,  4, 13, 29, 15, 20, 14, 11,  4, 18, 19,  0],\n",
      "        [10, 20,  8, 13, 29, 10,  8, 12, 15, 15, 20, 20, 13, 29,  0, 12, 15, 20,\n",
      "          4, 13, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
      "         30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30]])\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels shape: torch.Size([3, 54])\n",
      "Label_len shape: torch.Size([3])\n",
      "\n",
      "Processing sample 0\n",
      "Clipped label: tensor([ 7,  8, 17, 21,  8, 19, 24, 18, 29,  7, 24, 28, 10, 10, 27, 18,  8, 29,\n",
      "        18,  8, 19, 27, 29, 11, 27,  7,  8, 13, 13, 27, 29, 14, 11,  4, 21,  0,\n",
      "        13, 29, 19,  0, 13, 10,  8, 13, 29, 10,  8, 12, 15, 15, 20, 20, 13])\n",
      "Converted text: 'hirvitys hyökkäsi sitä lähinnä olevan tankin kimppuun'\n",
      "Text length: 53\n",
      "\n",
      "Processing sample 1\n",
      "Clipped label: tensor([27, 27, 13,  4, 18, 19, 27, 12, 12,  4, 29, 18,  8,  8, 18, 29, 19, 27,\n",
      "        12, 27, 13, 18, 20, 20, 13, 19,  0,  8, 18, 19,  4, 13, 29, 19,  0, 17,\n",
      "        10,  8, 18, 19, 20, 18, 19,  4, 13, 29, 15, 20, 14, 11,  4, 18, 19,  0])\n",
      "Converted text: 'äänestämme siis tämänsuuntaisten tarkistusten puolesta'\n",
      "Text length: 54\n",
      "\n",
      "Processing sample 2\n",
      "Clipped label: tensor([10, 20,  8, 13, 29, 10,  8, 12, 15, 15, 20, 20, 13, 29,  0, 12, 15, 20,\n",
      "         4, 13])\n",
      "Converted text: 'kuin kimppuun ampuen'\n",
      "Text length: 20\n",
      "\n",
      "Final ref: ['hirvitys hyökkäsi sitä lähinnä olevan tankin kimppuun', 'äänestämme siis tämänsuuntaisten tarkistusten puolesta', 'kuin kimppuun ampuen']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Labels shape: {labels.shape}\")\n",
    "print(f\"Label_len shape: {label_len.shape}\")\n",
    "ref = []\n",
    "for i in range(labels.shape[0]):  # This should iterate 3 times\n",
    "    single_label = labels[i]\n",
    "    length = label_len[i]\n",
    "    \n",
    "    print(f\"\\nProcessing sample {i}\")\n",
    "    clipped_label = single_label[:length]\n",
    "    print(f\"Clipped label: {clipped_label}\")\n",
    "   \n",
    "    text = alphabet.array_to_text(clipped_label)\n",
    "    print(f\"Converted text: '{text}'\")\n",
    "    print(f\"Text length: {len(text)}\")\n",
    "   \n",
    "    ref.append(text)\n",
    "\n",
    "print(f\"\\nFinal ref: {ref}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 505, 31])\n"
     ]
    }
   ],
   "source": [
    "output = model(audio)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 505, 31])\n",
      "['hirvityshyökkäsiitä lähinnä olevan tankin kimppuun', 'äänestämme siis tämäin suntaisten tarkistusten puolestan', 'kuin kimppuun ampuen']\n",
      "['hirvitys hyökkäsi sitä lähinnä olevan tankin kimppuun', 'äänestämme siis tämänsuuntaisten tarkistusten puolesta', 'kuin kimppuun ampuen']\n"
     ]
    }
   ],
   "source": [
    "dec = SimpleDecoder(alphabet=alphabet.alphabet)\n",
    "log_probs = F.log_softmax(output, dim=-1)\n",
    "#log_probs = F.log_softmax(output, dim=2).permute(1, 0, 2)\n",
    "print(log_probs.shape)\n",
    "decoded_batch = dec.decode(log_probs)\n",
    "cleaned_decoded = [str(text).replace('<blank>', '') for text in decoded_batch]\n",
    "print(cleaned_decoded)\n",
    "print(ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import List\n",
    "\n",
    "class Alphabet:\n",
    "    def __init__(self, alphabet_string = 'abcdefghijklmnopqrstuvwxyzåäö '):\n",
    "        self.alphabet = list(alphabet_string)\n",
    "        self.alphabet.append('<blank>')  # Adding blank token\n",
    "        self.char_to_index = {char: index for index, char in enumerate(self.alphabet)}\n",
    "        self.index_to_char = {index: char for index, char in enumerate(self.alphabet)}\n",
    "        self.blank_index = len(self.alphabet) - 1  # Blank is the last index\n",
    "\n",
    "    def text_to_array(self, text):\n",
    "        return [self.char_to_index[char] for char in str.lower(text) if char in self.char_to_index]\n",
    "\n",
    "    def array_to_text(self, array):\n",
    "        return ''.join(self.index_to_char.get(int(index), '<UNK>') for index in array)\n",
    "\n",
    "    def decode(self, log_probs: torch.Tensor, remove_blanks: bool = False) -> List[str]:\n",
    "        \"\"\"\n",
    "        Decode log probabilities to text using simple greedy decoding.\n",
    "        \n",
    "        Args:\n",
    "        log_probs (torch.Tensor): Log probabilities from the model\n",
    "                                  Shape: (batch_size, sequence_length, num_classes)\n",
    "        remove_blanks (bool): If True, remove all blank tokens from the output\n",
    "        \n",
    "        Returns:\n",
    "        List[str]: Decoded texts for each item in the batch\n",
    "        \"\"\"\n",
    "        # Get the most likely class at each step\n",
    "        predictions = torch.argmax(log_probs, dim=-1)  # Shape: (batch_size, sequence_length)\n",
    "        \n",
    "        batch_texts = []\n",
    "        for batch_item in predictions:\n",
    "            text = self._decode_prediction(batch_item, remove_blanks)\n",
    "            batch_texts.append(text)\n",
    "        \n",
    "        return batch_texts\n",
    "\n",
    "    def _decode_prediction(self, prediction: torch.Tensor, remove_blanks: bool) -> str:\n",
    "        \"\"\"\n",
    "        Decode a single prediction sequence to text.\n",
    "        \n",
    "        Args:\n",
    "        prediction (torch.Tensor): Prediction sequence for a single item\n",
    "                                   Shape: (sequence_length,)\n",
    "        remove_blanks (bool): If True, remove all blank tokens from the output\n",
    "        \n",
    "        Returns:\n",
    "        str: Decoded text\n",
    "        \"\"\"\n",
    "        decoded = []\n",
    "        previous = None\n",
    "        for p in prediction:\n",
    "            p = p.item()\n",
    "            if remove_blanks:\n",
    "                if p != self.blank_index and p != previous:\n",
    "                    if p < len(self.alphabet) - 1:  # Exclude blank token\n",
    "                        decoded.append(self.alphabet[p])\n",
    "            else:\n",
    "                if p != previous:\n",
    "                    if p < len(self.alphabet):  # Include blank token\n",
    "                        decoded.append(self.alphabet[p])\n",
    "            previous = p\n",
    "        \n",
    "        return ''.join(decoded)\n",
    "    \n",
    "ap = Alphabet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 505, 31])\n",
      "['hirvityshyökkäsiitä lähinnä olevan tankin kimppuun', 'äänestämme siis tämäin suntaisten tarkistusten puolestan', 'kuin kimppuun ampuen']\n",
      "['hirvitys hyökkäsi sitä lähinnä olevan tankin kimppuun', 'äänestämme siis tämänsuuntaisten tarkistusten puolesta', 'kuin kimppuun ampuen']\n"
     ]
    }
   ],
   "source": [
    "log_probs = F.log_softmax(output, dim=-1)\n",
    "#log_probs = F.log_softmax(output, dim=2).permute(1, 0, 2)\n",
    "print(log_probs.shape)\n",
    "decoded_batch = ap.decode(log_probs)\n",
    "cleaned_decoded = [str(text).replace('<blank>', '') for text in decoded_batch]\n",
    "print(cleaned_decoded)\n",
    "print(ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 505, 31])\n",
      "['hirvityshyökkäsiitä lähinnä olevan tankin kimppuun', 'äänestämme siis tämäin suntaisten tarkistusten puolestan', 'kuin kimppuun ampuen']\n",
      "['hirvitys hyökkäsi sitä lähinnä olevan tankin kimppuun', 'äänestämme siis tämänsuuntaisten tarkistusten puolesta', 'kuin kimppuun ampuen']\n"
     ]
    }
   ],
   "source": [
    "log_probs = F.log_softmax(output, dim=-1)\n",
    "#log_probs = F.log_softmax(output, dim=2).permute(1, 0, 2)\n",
    "print(log_probs.shape)\n",
    "decoded_batch = ap.decode(log_probs, remove_blanks=True)\n",
    "print(decoded_batch)\n",
    "print(ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = preprocess_audio([ds[0], ds[1], ds[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ref0 hirvitys hyökkäsi sitä lähinnä olevan tankin kimppuun\n",
      "dec0 hirvityshyökkäsiitä lähinnä olevan tankin kimppuun\n",
      "logprobs decoder shape torch.Size([3, 505, 31])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "audio_padded, labels_padded, audio_lengths, label_lengths = batch\n",
    "\n",
    "audio = torch.stack(audio_padded, dim=0)\n",
    "# Shape: (batch_size, max_label_length)\n",
    "labels = torch.stack(labels_padded, dim=0)\n",
    "input_lengths = torch.tensor(audio_lengths)\n",
    "target_lengths = torch.tensor(label_lengths)\n",
    "# compute loss\n",
    "output = model(audio)\n",
    "log_probs = F.log_softmax(output, dim=2).permute(1, 0, 2)\n",
    "# Calculate log_probs for decoding (without permute)\n",
    "log_probs_decode = F.log_softmax(output, dim=-1)\n",
    "# Decode using SimpleDecoder\n",
    "decoded_text = ap.decode(log_probs_decode, remove_blanks=True)\n",
    "#compute wer & cer\n",
    "ref = []\n",
    "for label, length in zip(labels, label_lengths):\n",
    "    clipped_label = label[:length]\n",
    "    ref.append(alphabet.array_to_text(clipped_label.cpu().numpy()))\n",
    "print(f\"\"\"\n",
    "ref0 {ref[0]}\n",
    "dec0 {decoded_text[0]}\n",
    "logprobs decoder shape {log_probs_decode.shape}\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
